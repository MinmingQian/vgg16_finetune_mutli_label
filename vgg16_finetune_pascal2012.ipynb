{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from load_cifar10 import load_cifar10_data\n",
    "from load_pascal2012 import load_pascal2012_data\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_model(img_rows, img_cols, channel=1, num_classes=None):\n",
    "    \"\"\"VGG 16 Model for Keras\n",
    "\n",
    "    Model Schema is based on \n",
    "    https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "\n",
    "    ImageNet Pretrained Weights \n",
    "    https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing\n",
    "\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of categories for our classification task\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(channel, img_rows, img_cols)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Add Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    # Loads ImageNet pre-trained data\n",
    "    model.load_weights('imagenet_models/vgg16_weights_th_dim_ordering_th_kernels.h5')\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    model.layers.pop()\n",
    "    for layer in model.layers: layer.trainable = False\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    # Uncomment below to set the first 10 layers to non-trainable (weights will not be updated)\n",
    "    #for layer in model.layers[:10]:\n",
    "    #    layer.trainable = False\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-5, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy',precision, recall, f1])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\t\t\n",
    "\n",
    "    Only computes a batch-wise average of precision.\t\t\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\t\t\n",
    "    how many selected items are relevant.\t\t\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\t\t\n",
    "\n",
    "    Only computes a batch-wise average of recall.\t\t\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\t\t\n",
    "    how many relevant items are selected.\t\t\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    pre = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*((pre*rec)/(pre+rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aeroplane_train.txt', 'bicycle_train.txt', 'bird_train.txt', 'boat_train.txt', 'bottle_train.txt', 'bus_train.txt', 'car_train.txt', 'cat_train.txt', 'chair_train.txt', 'cow_train.txt', 'diningtable_train.txt', 'dog_train.txt', 'horse_train.txt', 'motorbike_train.txt', 'person_train.txt', 'pottedplant_train.txt', 'sheep_train.txt', 'sofa_train.txt', 'train_train.txt', 'tvmonitor_train.txt']\n0: aeroplane_train.txt\n\n1: bicycle_train.txt\n\n2: bird_train.txt\n\n3: boat_train.txt\n\n4: bottle_train.txt\n\n5: bus_train.txt\n\n6: car_train.txt\n\n7: cat_train.txt\n\n8: chair_train.txt\n\n9: cow_train.txt\n\n10: diningtable_train.txt\n\n11: dog_train.txt\n\n12: horse_train.txt\n\n13: motorbike_train.txt\n\n14: person_train.txt\n\n15: pottedplant_train.txt\n\n16: sheep_train.txt\n\n17: sofa_train.txt\n\n18: train_train.txt\n\n19: tvmonitor_train.txt\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC2012/JPEGImages/2008_000033.jpg [0]aeroplane_train.txt\nVOC2012/JPEGImages/2008_000037.jpg [0]aeroplane_train.txt\nVOC2012/JPEGImages/2008_000151.jpg [0]aeroplane_train.txt\nVOC2012/JPEGImages/2008_000197.jpg [0]aeroplane_train.txt\nVOC2012/JPEGImages/2008_000291.jpg [0]aeroplane_train.txt\nVOC2012/JPEGImages/2008_000095.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000097.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000103.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000131.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000192.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000318.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000350.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000361.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000400.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000512.jpg [2]bird_train.txt\nVOC2012/JPEGImages/2008_000148.jpg [3]boat_train.txt\nVOC2012/JPEGImages/2008_000262.jpg [3]boat_train.txt\nVOC2012/JPEGImages/2008_000405.jpg [3]boat_train.txt\nVOC2012/JPEGImages/2008_000437.jpg [3]boat_train.txt\nVOC2012/JPEGImages/2008_000471.jpg [3]boat_train.txt\nVOC2012/JPEGImages/2008_000505.jpg [3]boat_train.txt\nVOC2012/JPEGImages/2008_000015.jpg [4]bottle_train.txt\nVOC2012/JPEGImages/2008_000154.jpg [4]bottle_train.txt\nVOC2012/JPEGImages/2008_000238.jpg [5]bus_train.txt\nVOC2012/JPEGImages/2008_000028.jpg [6]car_train.txt\nVOC2012/JPEGImages/2008_000074.jpg [6]car_train.txt\nVOC2012/JPEGImages/2008_000085.jpg [6]car_train.txt\nVOC2012/JPEGImages/2008_000105.jpg [6]car_train.txt\nVOC2012/JPEGImages/2008_000187.jpg [6]car_train.txt\nVOC2012/JPEGImages/2008_000356.jpg [6]car_train.txt\nVOC2012/JPEGImages/2008_000399.jpg [6]car_train.txt\nVOC2012/JPEGImages/2008_000060.jpg [7]cat_train.txt\nVOC2012/JPEGImages/2008_000181.jpg [7]cat_train.txt\nVOC2012/JPEGImages/2008_000502.jpg [7]cat_train.txt\nVOC2012/JPEGImages/2008_000089.jpg [8]chair_train.txt\nVOC2012/JPEGImages/2008_000335.jpg [9]cow_train.txt\nVOC2012/JPEGImages/2008_000019.jpg [11]dog_train.txt\nVOC2012/JPEGImages/2008_000053.jpg [11]dog_train.txt\nVOC2012/JPEGImages/2008_000066.jpg [11]dog_train.txt\nVOC2012/JPEGImages/2008_000162.jpg [11]dog_train.txt\nVOC2012/JPEGImages/2008_000336.jpg [11]dog_train.txt\nVOC2012/JPEGImages/2008_000428.jpg [12]horse_train.txt\nVOC2012/JPEGImages/2008_000207.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000217.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000236.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000255.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000259.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000266.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000283.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000289.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000313.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000316.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000342.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000364.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000365.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000380.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000392.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000415.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000416.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000422.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000426.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000436.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000442.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000443.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000445.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000447.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000448.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000455.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000461.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000480.jpg [14]person_train.txt\nVOC2012/JPEGImages/2008_000188.jpg [15]pottedplant_train.txt\nVOC2012/JPEGImages/2008_000287.jpg [15]pottedplant_train.txt\nVOC2012/JPEGImages/2008_000491.jpg [15]pottedplant_train.txt\nVOC2012/JPEGImages/2008_000045.jpg [18]train_train.txt\nVOC2012/JPEGImages/2008_000470.jpg [18]train_train.txt\nVOC2012/JPEGImages/2008_000309.jpg [19]tvmonitor_train.txt\nVOC2012/JPEGImages/2008_000348.jpg [19]tvmonitor_train.txt\nsamples counts: 77\n['aeroplane_val.txt', 'bicycle_val.txt', 'bird_val.txt', 'boat_val.txt', 'bottle_val.txt', 'bus_val.txt', 'car_val.txt', 'cat_val.txt', 'chair_val.txt', 'cow_val.txt', 'diningtable_val.txt', 'dog_val.txt', 'horse_val.txt', 'motorbike_val.txt', 'person_val.txt', 'pottedplant_val.txt', 'sheep_val.txt', 'sofa_val.txt', 'train_val.txt', 'tvmonitor_val.txt']\n0: aeroplane_val.txt\n\n1: bicycle_val.txt\n\n2: bird_val.txt\n\n3: boat_val.txt\n\n4: bottle_val.txt\n\n5: bus_val.txt\n\n6: car_val.txt\n\n7: cat_val.txt\n\n8: chair_val.txt\n\n9: cow_val.txt\n\n10: diningtable_val.txt\n\n11: dog_val.txt\n\n12: horse_val.txt\n\n13: motorbike_val.txt\n\n14: person_val.txt\n\n15: pottedplant_val.txt\n\n16: sheep_val.txt\n\n17: sofa_val.txt\n\n18: train_val.txt\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19: tvmonitor_val.txt\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC2012/JPEGImages/2008_000021.jpg [0]aeroplane_val.txt\nVOC2012/JPEGImages/2008_000064.jpg [0]aeroplane_val.txt\nVOC2012/JPEGImages/2008_000466.jpg [1]bicycle_val.txt\nVOC2012/JPEGImages/2008_000054.jpg [2]bird_val.txt\nVOC2012/JPEGImages/2008_000123.jpg [2]bird_val.txt\nVOC2012/JPEGImages/2008_000134.jpg [2]bird_val.txt\nVOC2012/JPEGImages/2008_000339.jpg [2]bird_val.txt\nVOC2012/JPEGImages/2008_000472.jpg [2]bird_val.txt\nVOC2012/JPEGImages/2008_000007.jpg [3]boat_val.txt\nVOC2012/JPEGImages/2008_000120.jpg [3]boat_val.txt\nVOC2012/JPEGImages/2008_000140.jpg [3]boat_val.txt\nVOC2012/JPEGImages/2008_000414.jpg [3]boat_val.txt\nVOC2012/JPEGImages/2008_000272.jpg [4]bottle_val.txt\nVOC2012/JPEGImages/2008_000075.jpg [5]bus_val.txt\nVOC2012/JPEGImages/2008_000027.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000042.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000050.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000163.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000174.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000253.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000304.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000457.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000501.jpg [6]car_val.txt\nVOC2012/JPEGImages/2008_000056.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000062.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000116.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000182.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000306.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000345.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000358.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000401.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000464.jpg [7]cat_val.txt\nVOC2012/JPEGImages/2008_000107.jpg [8]chair_val.txt\nVOC2012/JPEGImages/2008_000498.jpg [8]chair_val.txt\nVOC2012/JPEGImages/2008_000009.jpg [9]cow_val.txt\nVOC2012/JPEGImages/2008_000073.jpg [9]cow_val.txt\nVOC2012/JPEGImages/2008_000078.jpg [11]dog_val.txt\nVOC2012/JPEGImages/2008_000080.jpg [11]dog_val.txt\nVOC2012/JPEGImages/2008_000183.jpg [11]dog_val.txt\nVOC2012/JPEGImages/2008_000239.jpg [11]dog_val.txt\nVOC2012/JPEGImages/2008_000076.jpg [12]horse_val.txt\nVOC2012/JPEGImages/2008_000177.jpg [12]horse_val.txt\nVOC2012/JPEGImages/2008_000219.jpg [12]horse_val.txt\nVOC2012/JPEGImages/2008_000378.jpg [13]motorbike_val.txt\nVOC2012/JPEGImages/2008_000204.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000213.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000215.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000223.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000233.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000234.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000243.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000254.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000264.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000271.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000277.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000298.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000307.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000340.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000354.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000359.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000376.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000382.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000406.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000407.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000413.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000424.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000452.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000474.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000475.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000481.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000496.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000510.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000511.jpg [14]person_val.txt\nVOC2012/JPEGImages/2008_000391.jpg [15]pottedplant_val.txt\nVOC2012/JPEGImages/2008_000084.jpg [16]sheep_val.txt\nVOC2012/JPEGImages/2008_000257.jpg [16]sheep_val.txt\nVOC2012/JPEGImages/2008_000190.jpg [18]train_val.txt\nVOC2012/JPEGImages/2008_000373.jpg [18]train_val.txt\nVOC2012/JPEGImages/2008_000002.jpg [19]tvmonitor_val.txt\nVOC2012/JPEGImages/2008_000016.jpg [19]tvmonitor_val.txt\nVOC2012/JPEGImages/2008_000244.jpg [19]tvmonitor_val.txt\nsamples counts: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianminming/keras/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 20\n",
    "batch_size = 16 \n",
    "nb_epoch = 10\n",
    "\n",
    "# Load Cifar10 data. Please implement your own load_data() module for your own dataset\n",
    "# X_train, Y_train, X_valid, Y_valid = load_cifar10_data(img_rows, img_cols)\n",
    "X_train, Y_train, X_valid, Y_valid = load_pascal2012_data(img_rows, img_cols)\n",
    "\n",
    "# Load our model\n",
    "model = vgg16_model(img_rows, img_cols, channel, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}